#!/usr/bin/env python3
"""
ì˜¤ë‹µ ë¶„ì„ ìŠ¤í¬ë¦½íŠ¸

Test ë°ì´í„°ì—ì„œ ì˜¤ë‹µì„ ì°¾ì•„ì„œ ê° í´ë˜ìŠ¤ë³„ë¡œ 
ì˜ëª» ì˜ˆì¸¡í•œ confidenceê°€ ë†’ì€ ìˆœìœ¼ë¡œ ì •ë ¬í•˜ì—¬ ì¶œë ¥
"""

import sys
import os
import argparse
from pathlib import Path
import pandas as pd

project_root = Path(__file__).parent
sys.path.append(str(project_root))

from utils.device_manager import DeviceManager
from utils.env_loader import load_env_once
from image_classification.inference import ImageClassifierInference

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_env_once()


def analyze_errors(model_path: str, test_data_path: str, top_k: int = 10, output_path: str = None):
    """
    ì˜¤ë‹µ ë¶„ì„ ì‹¤í–‰
    
    Args:
        model_path: ëª¨ë¸ ê²½ë¡œ
        test_data_path: í…ŒìŠ¤íŠ¸ ë°ì´í„° CSV ê²½ë¡œ
        top_k: ê° í´ë˜ìŠ¤ë³„ ìƒìœ„ kê°œ ì¶œë ¥
        output_path: ê²°ê³¼ ì €ì¥ ê²½ë¡œ (ì„ íƒ)
    """
    # í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ
    print(f"ğŸ“‚ í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ: {test_data_path}")
    test_df = pd.read_csv(test_data_path)
    print(f"   ì´ {len(test_df)}ê°œ ìƒ˜í”Œ")
    
    # ì¶”ë¡  ì—”ì§„ ì´ˆê¸°í™”
    print(f"\nğŸ”§ ëª¨ë¸ ë¡œë“œ: {model_path}")
    device = DeviceManager.get_device()
    inference_engine = ImageClassifierInference(model_path=model_path, device=device)
    
    class_names = inference_engine.class_names
    print(f"   í´ë˜ìŠ¤: {class_names}")
    
    # ì´ë¯¸ì§€ ê²½ë¡œ ì»¬ëŸ¼ í™•ì¸
    image_col = 'image_path' if 'image_path' in test_df.columns else 'path'
    label_col = 'image_type' if 'image_type' in test_df.columns else 'label'
    
    image_paths = test_df[image_col].tolist()
    true_labels = test_df[label_col].tolist()
    
    # ë°°ì¹˜ ì˜ˆì¸¡
    print(f"\nğŸ”® ì˜ˆì¸¡ ì‹¤í–‰ ì¤‘...")
    predictions = inference_engine.predict_batch(
        image_paths=image_paths,
        batch_size=64,
        return_probabilities=True
    )
    
    # ê²°ê³¼ DataFrame ìƒì„±
    # product_id ì»¬ëŸ¼ì´ ìˆìœ¼ë©´ í¬í•¨
    has_product_id = 'product_id' in test_df.columns
    results = []
    for i, pred in enumerate(predictions):
        true_label = true_labels[i]
        pred_label = pred.get('predicted_class', 'ERROR')
        confidence = pred.get('confidence', 0.0)
        probs = pred.get('probabilities', {})

        is_correct = (str(true_label) == str(pred_label))

        row = {
            'image_path': image_paths[i],
            'true_label': true_label,
            'predicted_label': pred_label,
            'confidence': confidence,
            'is_correct': is_correct,
            **{f'prob_{c}': probs.get(c, 0.0) for c in class_names}
        }
        if has_product_id:
            row['product_id'] = test_df.iloc[i]['product_id']
        results.append(row)

    results_df = pd.DataFrame(results)
    
    # ì „ì²´ ì •í™•ë„
    accuracy = results_df['is_correct'].mean() * 100
    total_errors = (~results_df['is_correct']).sum()
    print(f"\nğŸ“Š ì „ì²´ ì •í™•ë„: {accuracy:.2f}% (ì˜¤ë‹µ: {total_errors}ê°œ)")
    
    # ì˜¤ë‹µë§Œ í•„í„°ë§
    errors_df = results_df[~results_df['is_correct']].copy()
    
    if len(errors_df) == 0:
        print("\nâœ… ì˜¤ë‹µì´ ì—†ìŠµë‹ˆë‹¤!")
        return results_df
    
    # ê° í´ë˜ìŠ¤ë³„ ì˜¤ë‹µ ë¶„ì„
    print("\n" + "=" * 80)
    print("ğŸ” í´ë˜ìŠ¤ë³„ ì˜¤ë‹µ ë¶„ì„ (ì˜ëª» ì˜ˆì¸¡í•œ confidenceê°€ ë†’ì€ ìˆœ)")
    print("=" * 80)
    
    all_class_errors = {}
    
    for true_class in class_names:
        # í•´ë‹¹ í´ë˜ìŠ¤ì˜ ìƒ˜í”Œ ì¤‘ ì˜¤ë‹µì¸ ê²ƒë“¤
        class_errors = errors_df[errors_df['true_label'] == true_class].copy()
        
        if len(class_errors) == 0:
            print(f"\nğŸ“Œ [{true_class}] ì˜¤ë‹µ ì—†ìŒ")
            continue
        
        # confidence(ì˜ëª» ì˜ˆì¸¡í•œ í´ë˜ìŠ¤ì˜ í™•ë¥ ) ë†’ì€ ìˆœìœ¼ë¡œ ì •ë ¬
        class_errors = class_errors.sort_values('confidence', ascending=False)
        
        total_class_samples = len(results_df[results_df['true_label'] == true_class])
        error_rate = len(class_errors) / total_class_samples * 100
        
        print(f"\nğŸ“Œ [{true_class}] ì˜¤ë‹µ: {len(class_errors)}ê°œ / {total_class_samples}ê°œ (ì˜¤ë‹µë¥ : {error_rate:.1f}%)")
        print("-" * 80)
        
        # ìƒìœ„ kê°œ ì¶œë ¥
        for idx, row in class_errors.head(top_k).iterrows():
            print(f"  ì´ë¯¸ì§€: {row['image_path']}")
            print(f"    ì •ë‹µ: {row['true_label']} â†’ ì˜ˆì¸¡: {row['predicted_label']} (conf: {row['confidence']:.4f})")
            
            # ê° í´ë˜ìŠ¤ í™•ë¥  í‘œì‹œ
            prob_str = " | ".join([f"{c}: {row[f'prob_{c}']:.3f}" for c in class_names])
            print(f"    í™•ë¥ : {prob_str}")
            print()
        
        all_class_errors[true_class] = class_errors
    
    # ì˜ˆì¸¡ í´ë˜ìŠ¤ë³„ ë¶„ì„ (ì–´ë–¤ í´ë˜ìŠ¤ë¡œ ì˜ëª» ì˜ˆì¸¡í–ˆëŠ”ì§€)
    print("\n" + "=" * 80)
    print("ğŸ¯ ì˜ëª» ì˜ˆì¸¡ëœ í´ë˜ìŠ¤ë³„ ë¶„ì„ (ì´ í´ë˜ìŠ¤ë¡œ ì˜ëª» ì˜ˆì¸¡í•œ ê²ƒë“¤)")
    print("=" * 80)
    
    for pred_class in class_names:
        # ì´ í´ë˜ìŠ¤ë¡œ ì˜ëª» ì˜ˆì¸¡ëœ ê²ƒë“¤
        wrong_as_this = errors_df[errors_df['predicted_label'] == pred_class].copy()
        
        if len(wrong_as_this) == 0:
            print(f"\nğŸ¯ [{pred_class}]ë¡œ ì˜ëª» ì˜ˆì¸¡ëœ ìƒ˜í”Œ ì—†ìŒ")
            continue
        
        wrong_as_this = wrong_as_this.sort_values('confidence', ascending=False)
        
        print(f"\nğŸ¯ [{pred_class}]ë¡œ ì˜ëª» ì˜ˆì¸¡ëœ ìƒ˜í”Œ: {len(wrong_as_this)}ê°œ")
        print("-" * 80)
        
        # ì‹¤ì œ í´ë˜ìŠ¤ ë¶„í¬
        true_dist = wrong_as_this['true_label'].value_counts()
        print(f"  ì‹¤ì œ í´ë˜ìŠ¤ ë¶„í¬: {dict(true_dist)}")
        
        # ìƒìœ„ kê°œ ì¶œë ¥
        for idx, row in wrong_as_this.head(top_k).iterrows():
            print(f"  ì´ë¯¸ì§€: {row['image_path']}")
            print(f"    ì •ë‹µ: {row['true_label']} â†’ ì˜ˆì¸¡: {row['predicted_label']} (conf: {row['confidence']:.4f})")
            print()
    
    # Confusion Matrix ìš”ì•½
    print("\n" + "=" * 80)
    print("ğŸ“ˆ Confusion Matrix ìš”ì•½")
    print("=" * 80)
    
    confusion = pd.crosstab(
        errors_df['true_label'], 
        errors_df['predicted_label'],
        margins=True
    )
    print(confusion)
    
    # ê²°ê³¼ ì €ì¥ (ë‹¨ìˆœí™”ëœ í˜•ì‹)
    if output_path:
        # í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì„ íƒ (product_idê°€ ìˆìœ¼ë©´ í¬í•¨)
        cols = ['true_label', 'predicted_label', 'confidence', 'image_path']
        if has_product_id:
            cols.insert(0, 'product_id')
        simple_errors = errors_df[cols].copy()

        # 1ì°¨: true_label, 2ì°¨: confidence ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬
        simple_errors = simple_errors.sort_values(
            ['true_label', 'confidence'], 
            ascending=[True, False]
        )

        # true_labelì´ ë°”ë€” ë•Œë§ˆë‹¤ ë¹ˆ ì¤„ ì¶”ê°€
        rows_with_separator = []
        prev_label = None
        for _, row in simple_errors.iterrows():
            if prev_label is not None and row['true_label'] != prev_label:
                # ë¹ˆ ì¤„ ì¶”ê°€
                empty_row = {col: '' for col in cols}
                rows_with_separator.append(empty_row)
            rows_with_separator.append(row.to_dict())
            prev_label = row['true_label']

        final_df = pd.DataFrame(rows_with_separator)
        
        # ë””ë ‰í† ë¦¬ ìƒì„±
        if os.path.dirname(output_path):
            os.makedirs(os.path.dirname(output_path), exist_ok=True)
            
        final_df.to_csv(output_path, index=False)
        print(f"\nğŸ’¾ ì˜¤ë‹µ ë°ì´í„° ì €ì¥: {output_path}")
    
    return results_df, errors_df


def main():
    parser = argparse.ArgumentParser(description='ì˜¤ë‹µ ë¶„ì„')
    parser.add_argument('--model', type=str, 
                       default='results/run_20260106_140031_32d4e2c3/model/best_model.pth',
                       help='ëª¨ë¸ ê²½ë¡œ')
    parser.add_argument('--test-data', type=str,
                       default='data/test_data.csv',
                       help='í…ŒìŠ¤íŠ¸ ë°ì´í„° ê²½ë¡œ')
    parser.add_argument('--top-k', type=int, default=40,
                       help='ê° í´ë˜ìŠ¤ë³„ ìƒìœ„ kê°œ ì¶œë ¥')
    parser.add_argument('--output', type=str, default='error_results/error_analysis_test.csv',
                       help='ì˜¤ë‹µ ë°ì´í„° ì €ì¥ ê²½ë¡œ')
    
    args = parser.parse_args()
    
    analyze_errors(
        model_path=args.model,
        test_data_path=args.test_data,
        top_k=args.top_k,
        output_path=args.output
    )


if __name__ == "__main__":
    main()
