# image_classification/trainer.py
"""
ì´ë¯¸ì§€ ë¶„ë¥˜ ëª¨ë¸ í•™ìŠµ í´ë˜ìŠ¤

ImageClassifierTrainer:
- ëª¨ë¸ í•™ìŠµ ë° ê²€ì¦
- ì†ì‹¤ í•¨ìˆ˜ ë° ì˜µí‹°ë§ˆì´ì € ê´€ë¦¬
- í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ë§
- ì¡°ê¸° ì¢…ë£Œ (Early Stopping)
- ì²´í¬í¬ì¸íŠ¸ ì €ì¥
"""

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
import numpy as np
import os
from typing import Dict, Any, Optional, Tuple, List
import logging
import time
from datetime import datetime
import json
import copy
from tqdm import tqdm
import matplotlib.pyplot as plt
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.utils.class_weight import compute_class_weight
import seaborn as sns
from .losses import FocalLoss, WeightedFocalLoss

try:
    import wandb
    WANDB_AVAILABLE = True
except ImportError:
    WANDB_AVAILABLE = False

logger = logging.getLogger(__name__)

class ImageClassifierTrainer:
    """ì´ë¯¸ì§€ ë¶„ë¥˜ ëª¨ë¸ í•™ìŠµ í´ë˜ìŠ¤"""
    
    def __init__(self, 
                 model: nn.Module,
                 train_loader: DataLoader,
                 val_loader: DataLoader,
                 config: Dict[str, Any],
                 device: torch.device = None):
        """
        Args:
            model: í•™ìŠµí•  ëª¨ë¸
            train_loader: í•™ìŠµ ë°ì´í„° ë¡œë”
            val_loader: ê²€ì¦ ë°ì´í„° ë¡œë”
            config: í•™ìŠµ ì„¤ì •
            device: ë””ë°”ì´ìŠ¤
        """
        self.model = model
        self.train_loader = train_loader
        self.val_loader = val_loader
        self.config = config
        # ë””ë°”ì´ìŠ¤ ê´€ë¦¬ì ì‚¬ìš© (importëŠ” í•„ìš”ì‹œ ì¶”ê°€)
        if device is not None:
            self.device = device
        else:
            try:
                from ..utils.device_manager import DeviceManager
                self.device = DeviceManager.get_device()
            except ImportError:
                self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        
        # ëª¨ë¸ì„ ë””ë°”ì´ìŠ¤ë¡œ ì´ë™
        self.model.to(self.device)
        
        # í•™ìŠµ ì„¤ì • ì¶”ì¶œ
        training_config = config.get('training', {})
        self.epochs = training_config.get('epochs', 50)
        self.learning_rate = training_config.get('learning_rate', 1e-4)
        self.weight_decay = training_config.get('weight_decay', 1e-4)
        self.patience = training_config.get('patience', 10)
        self.min_delta = training_config.get('min_delta', 0.001)
        self.use_class_weights = training_config.get('use_class_weights', True)
        self.gradient_clip_norm = training_config.get('gradient_clip_norm', 1.0)
        
        # ëª¨ë¸ ì„¤ì •
        model_config = config.get('model', {})
        self.freeze_backbone_epochs = model_config.get('freeze_backbone_epochs', 5)
        self.backbone_lr = training_config.get('backbone_lr', self.learning_rate * 0.1)
        
        # ë””ë ‰í† ë¦¬ ì„¤ì •
        paths_config = config.get('paths', {})
        self.model_dir = paths_config.get('model_dir', 'models')
        self.log_dir = paths_config.get('log_dir', 'logs')
        self.checkpoint_dir = paths_config.get('checkpoint_dir', 'checkpoints')
        
        # ë””ë ‰í† ë¦¬ ìƒì„± (ì•ˆì „ì„± ì²´í¬)
        for dir_name, dir_path in [
            ('model_dir', self.model_dir),
            ('log_dir', self.log_dir), 
            ('checkpoint_dir', self.checkpoint_dir)
        ]:
            if dir_path and isinstance(dir_path, str):
                os.makedirs(dir_path, exist_ok=True)
            else:
                logger.warning(f"ìœ íš¨í•˜ì§€ ì•Šì€ ë””ë ‰í† ë¦¬ ê²½ë¡œ {dir_name}: {dir_path}")
        
        # ì†ì‹¤ í•¨ìˆ˜ ì„¤ì •
        self.criterion = self._setup_criterion()
        
        # ì˜µí‹°ë§ˆì´ì € ì„¤ì •
        self.optimizer = self._setup_optimizer()
        
        # ìŠ¤ì¼€ì¤„ëŸ¬ ì„¤ì •
        self.scheduler = self._setup_scheduler()
        
        # í•™ìŠµ ê¸°ë¡
        self.train_losses = []
        self.val_losses = []
        self.train_accuracies = []
        self.val_accuracies = []
        self.learning_rates = []
        
        # ì¡°ê¸° ì¢…ë£Œ ë³€ìˆ˜
        self.best_val_loss = float('inf')
        self.best_val_acc = 0.0
        self.epochs_without_improvement = 0
        self.best_model_state = None
        
        # wandb ì„¤ì •
        self.wandb_enabled = config.get('logging', {}).get('use_wandb', False)
        self.wandb_project = config.get('logging', {}).get('wandb_project', 'image-classification')
        
        logger.info(f"íŠ¸ë ˆì´ë„ˆ ì´ˆê¸°í™” ì™„ë£Œ - ë””ë°”ì´ìŠ¤: {self.device}")
        if self.wandb_enabled and WANDB_AVAILABLE:
            logger.info("wandb ë¡œê¹… í™œì„±í™”")
        elif self.wandb_enabled and not WANDB_AVAILABLE:
            logger.warning("wandbê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë¡œê¹…ì´ ë¹„í™œì„±í™”ë©ë‹ˆë‹¤.")
    
    def _setup_criterion(self) -> nn.Module:
        """ì†ì‹¤ í•¨ìˆ˜ ì„¤ì •"""
        training_config = self.config.get('training', {})
        use_focal_loss = training_config.get('focal_loss', False)
        
        if use_focal_loss:
            # Focal Loss ì‚¬ìš©
            alpha = training_config.get('focal_alpha', 0.25)
            gamma = training_config.get('focal_gamma', 2.0)
            
            if self.use_class_weights:
                # í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ê³„ì‚°
                class_weights = self._compute_class_weights()
                criterion = WeightedFocalLoss(
                    class_weights=class_weights,
                    alpha=alpha,
                    gamma=gamma
                )
                logger.info(f"í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ë¥¼ ì‚¬ìš©í•œ Focal Loss ì„¤ì • (Î±={alpha}, Î³={gamma})")
            else:
                criterion = FocalLoss(alpha=alpha, gamma=gamma)
                logger.info(f"Focal Loss ì„¤ì • (Î±={alpha}, Î³={gamma})")
        else:
            # í‘œì¤€ Cross Entropy ì‚¬ìš©
            if self.use_class_weights:
                class_weights = self._compute_class_weights()
                criterion = nn.CrossEntropyLoss(weight=class_weights)
                logger.info("í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ë¥¼ ì‚¬ìš©í•œ CrossEntropyLoss ì„¤ì •")
            else:
                criterion = nn.CrossEntropyLoss()
                logger.info("í‘œì¤€ CrossEntropyLoss ì„¤ì •")
        
        return criterion
    
    def _compute_class_weights(self) -> torch.Tensor:
        """í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ê³„ì‚°"""
        # í•™ìŠµ ë°ì´í„°ì—ì„œ í´ë˜ìŠ¤ ë¶„í¬ ê³„ì‚°
        all_labels = []
        for _, labels in self.train_loader:
            all_labels.extend(labels.numpy())
        
        # sklearnì„ ì‚¬ìš©í•œ í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ê³„ì‚°
        unique_classes = np.unique(all_labels)
        class_weights = compute_class_weight(
            'balanced',
            classes=unique_classes,
            y=all_labels
        )
        
        # Tensorë¡œ ë³€í™˜í•˜ì—¬ deviceë¡œ ì´ë™
        class_weights = torch.FloatTensor(class_weights).to(self.device)
        logger.info(f"í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜: {class_weights.cpu().numpy()}")
        
        return class_weights
    
    def _param_groups(self):
        """ë°±ë³¸ê³¼ í—¤ë“œë¡œ íŒŒë¼ë¯¸í„° ê·¸ë£¹ ë¶„ë¦¬"""
        backbone_params = []
        head_params = []
        
        for name, param in self.model.named_parameters():
            if not param.requires_grad:
                continue
            if name.startswith("backbone."):
                backbone_params.append(param)
            else:
                head_params.append(param)
        
        param_groups = [
            {'params': head_params, 'lr': self.learning_rate},
            {'params': backbone_params, 'lr': self.backbone_lr}
        ]
        
        logger.debug(f"íŒŒë¼ë¯¸í„° ê·¸ë£¹ - í—¤ë“œ: {len(head_params)}ê°œ, ë°±ë³¸: {len(backbone_params)}ê°œ")
        return param_groups
    
    def _setup_optimizer(self) -> optim.Optimizer:
        """ì˜µí‹°ë§ˆì´ì € ì„¤ì • (íŒŒë¼ë¯¸í„° ê·¸ë£¹ë³„ í•™ìŠµë¥ )"""
        optimizer_name = self.config.get('training', {}).get('optimizer', 'adamw').lower()
        param_groups = self._param_groups()
        
        if optimizer_name == 'adamw':
            optimizer = optim.AdamW(
                param_groups,
                lr=self.learning_rate,
                weight_decay=self.weight_decay
            )
        elif optimizer_name == 'adam':
            optimizer = optim.Adam(
                param_groups,
                lr=self.learning_rate,
                weight_decay=self.weight_decay
            )
        elif optimizer_name == 'sgd':
            optimizer = optim.SGD(
                param_groups,
                lr=self.learning_rate,
                momentum=0.9,
                weight_decay=self.weight_decay
            )
        else:
            raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ì˜µí‹°ë§ˆì´ì €: {optimizer_name}")
        
        logger.info(f"ì˜µí‹°ë§ˆì´ì € ì„¤ì •: {optimizer_name.upper()}, í—¤ë“œ LR: {self.learning_rate}, ë°±ë³¸ LR: {self.backbone_lr}")
        return optimizer
    
    def _rebuild_optimizer_and_scheduler(self):
        """freeze/unfreeze ì‹œ ì˜µí‹°ë§ˆì´ì €ì™€ ìŠ¤ì¼€ì¤„ëŸ¬ ì¬êµ¬ì„±"""
        self.optimizer = self._setup_optimizer()
        self.scheduler = self._setup_scheduler()
        logger.info("ì˜µí‹°ë§ˆì´ì €ì™€ ìŠ¤ì¼€ì¤„ëŸ¬ ì¬êµ¬ì„± ì™„ë£Œ")
    
    def _setup_scheduler(self) -> Optional[optim.lr_scheduler._LRScheduler]:
        """í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ëŸ¬ ì„¤ì •"""
        scheduler_name = self.config.get('training', {}).get('scheduler', 'cosine').lower()
        
        if scheduler_name == 'cosine':
            scheduler = optim.lr_scheduler.CosineAnnealingLR(
                self.optimizer, T_max=self.epochs
            )
        elif scheduler_name == 'step':
            scheduler = optim.lr_scheduler.StepLR(
                self.optimizer, step_size=10, gamma=0.1
            )
        elif scheduler_name == 'plateau':
            scheduler_patience = self.config.get('training', {}).get('scheduler_patience', 7)
            scheduler = optim.lr_scheduler.ReduceLROnPlateau(
                self.optimizer, mode='min', factor=0.3, patience=scheduler_patience, verbose=True
            )
        elif scheduler_name == 'none':
            scheduler = None
        else:
            raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ìŠ¤ì¼€ì¤„ëŸ¬: {scheduler_name}")
        
        if scheduler:
            logger.info(f"ìŠ¤ì¼€ì¤„ëŸ¬ ì„¤ì •: {scheduler_name.upper()}")
        else:
            logger.info("ìŠ¤ì¼€ì¤„ëŸ¬ ì‚¬ìš© ì•ˆ í•¨")
        
        return scheduler
    
    def train_epoch(self) -> Tuple[float, float]:
        """í•œ ì—í¬í¬ í•™ìŠµ"""
        self.model.train()
        total_loss = 0.0
        correct = 0
        total = 0
        
        progress_bar = tqdm(self.train_loader, desc="Training", leave=False)
        
        for batch_idx, (data, target) in enumerate(progress_bar):
            data, target = data.to(self.device), target.to(self.device)
            
            # ìˆœì „íŒŒ
            self.optimizer.zero_grad()
            output = self.model(data)
            loss = self.criterion(output, target)
            
            # ì—­ì „íŒŒ
            loss.backward()
            
            # ê·¸ë˜ë””ì–¸íŠ¸ í´ë¦¬í•‘
            if self.gradient_clip_norm > 0:
                torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.gradient_clip_norm)
            
            self.optimizer.step()
            
            # í†µê³„ ê³„ì‚°
            total_loss += loss.item()
            _, predicted = output.max(1)
            total += target.size(0)
            correct += predicted.eq(target).sum().item()
            
            # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
            accuracy = 100. * correct / total
            progress_bar.set_postfix({
                'Loss': f'{loss.item():.4f}',
                'Acc': f'{accuracy:.2f}%'
            })
        
        epoch_loss = total_loss / len(self.train_loader)
        epoch_acc = 100. * correct / total
        
        return epoch_loss, epoch_acc
    
    def validate_epoch(self) -> Tuple[float, float]:
        """í•œ ì—í¬í¬ ê²€ì¦"""
        self.model.eval()
        total_loss = 0.0
        correct = 0
        total = 0
        
        with torch.no_grad():
            for data, target in tqdm(self.val_loader, desc="Validation", leave=False):
                data, target = data.to(self.device), target.to(self.device)
                
                output = self.model(data)
                loss = self.criterion(output, target)
                
                total_loss += loss.item()
                _, predicted = output.max(1)
                total += target.size(0)
                correct += predicted.eq(target).sum().item()
        
        epoch_loss = total_loss / len(self.val_loader)
        epoch_acc = 100. * correct / total
        
        return epoch_loss, epoch_acc
    
    def train(self) -> Dict[str, Any]:
        """ì „ì²´ í•™ìŠµ í”„ë¡œì„¸ìŠ¤"""
        logger.info("=" * 60)
        logger.info("ğŸš€ í•™ìŠµ ì‹œì‘")
        logger.info("=" * 60)
        
        start_time = time.time()
        
        # ì´ˆê¸° freeze ì„¤ì •
        freeze_epochs = max(0, int(self.freeze_backbone_epochs))
        if freeze_epochs > 0:
            self.model.freeze_backbone()
            # BatchNorm í†µê³„ ê³ ì •: ë°±ë³¸ë§Œ eval ëª¨ë“œ
            if hasattr(self.model, 'backbone'):
                self.model.backbone.eval()
            self._rebuild_optimizer_and_scheduler()
            logger.info(f"ë°±ë³¸ ê³ ì •: ì²˜ìŒ {freeze_epochs} ì—í¬í¬ (BatchNorm í†µê³„ ê³ ì •)")
        
        for epoch in range(1, self.epochs + 1):
            epoch_start_time = time.time()
            
            # freeze ê¸°ê°„ ì¢…ë£Œ ì§í›„ì— unfreeze
            if freeze_epochs > 0 and epoch == freeze_epochs + 1:
                self.model.unfreeze_backbone()
                # BatchNorm í•™ìŠµ ì¬ê°œ
                if hasattr(self.model, 'backbone'):
                    self.model.backbone.train()
                self._rebuild_optimizer_and_scheduler()
                logger.info(f"ì—í¬í¬ {epoch}: ë°±ë³¸ ê³ ì • í•´ì œ ë° ì˜µí‹°ë§ˆì´ì € ì¬êµ¬ì„±")
            
            # í•™ìŠµ
            train_loss, train_acc = self.train_epoch()
            
            # ê²€ì¦
            val_loss, val_acc = self.validate_epoch()
            
            # ìŠ¤ì¼€ì¤„ëŸ¬ ì—…ë°ì´íŠ¸
            if self.scheduler:
                if isinstance(self.scheduler, optim.lr_scheduler.ReduceLROnPlateau):
                    self.scheduler.step(val_loss)
                else:
                    self.scheduler.step()
            
            # í˜„ì¬ í•™ìŠµë¥  ê¸°ë¡
            current_lr = self.optimizer.param_groups[0]['lr']
            self.learning_rates.append(current_lr)
            
            # ê²°ê³¼ ê¸°ë¡
            self.train_losses.append(train_loss)
            self.val_losses.append(val_loss)
            self.train_accuracies.append(train_acc)
            self.val_accuracies.append(val_acc)
            
            # ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì €ì¥
            if val_loss < self.best_val_loss:
                self.best_val_loss = val_loss
                self.best_val_acc = val_acc
                self.epochs_without_improvement = 0
                self.best_model_state = copy.deepcopy(self.model.state_dict())
                self.save_checkpoint(epoch, is_best=True)
            else:
                self.epochs_without_improvement += 1
            
            # ì—í¬í¬ ì‹œê°„ ê³„ì‚°
            epoch_time = time.time() - epoch_start_time
            
            # ì§„í–‰ ìƒí™© ì¶œë ¥
            print(f"Epoch {epoch:3d}/{self.epochs} | "
                  f"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:5.2f}% | "
                  f"Val Loss: {val_loss:.4f} | Val Acc: {val_acc:5.2f}% | "
                  f"LR: {current_lr:.2e} | Time: {epoch_time:.1f}s")
            
            # wandb ë¡œê¹…
            if self.wandb_enabled and WANDB_AVAILABLE and wandb.run:
                wandb.log({
                    'epoch': epoch,
                    'train_loss': train_loss,
                    'train_accuracy': train_acc,
                    'val_loss': val_loss,
                    'val_accuracy': val_acc,
                    'learning_rate': current_lr,
                    'epoch_time': epoch_time,
                    'best_val_loss': self.best_val_loss,
                    'best_val_acc': self.best_val_acc,
                    'epochs_without_improvement': self.epochs_without_improvement
                })
            
            # ì¡°ê¸° ì¢…ë£Œ í™•ì¸
            if self.epochs_without_improvement >= self.patience:
                logger.info(f"ì¡°ê¸° ì¢…ë£Œ: {self.patience} ì—í¬í¬ ë™ì•ˆ ê°œì„  ì—†ìŒ")
                break
        
        # ìµœê³  ëª¨ë¸ë¡œ ë³µì›
        if self.best_model_state:
            self.model.load_state_dict(self.best_model_state)
            logger.info("ìµœê³  ì„±ëŠ¥ ëª¨ë¸ë¡œ ë³µì›")
        
        total_time = time.time() - start_time
        
        # í•™ìŠµ ê²°ê³¼ ìš”ì•½
        training_summary = {
            'total_epochs': epoch,
            'best_val_loss': self.best_val_loss,
            'best_val_accuracy': self.best_val_acc,
            'training_time': total_time,
            'final_learning_rate': self.optimizer.param_groups[0]['lr']
        }
        
        logger.info("=" * 60)
        logger.info("âœ… í•™ìŠµ ì™„ë£Œ")
        logger.info(f"ìµœê³  ê²€ì¦ ì •í™•ë„: {self.best_val_acc:.2f}%")
        logger.info(f"ìµœê³  ê²€ì¦ ì†ì‹¤: {self.best_val_loss:.4f}")
        logger.info(f"ì´ í•™ìŠµ ì‹œê°„: {total_time:.1f}ì´ˆ")
        logger.info("=" * 60)
        
        # ê²°ê³¼ ì €ì¥
        self.save_training_results(training_summary)
        self.plot_training_curves()
        
        return training_summary
    
    def save_checkpoint(self, epoch: int, is_best: bool = False):
        """ì²´í¬í¬ì¸íŠ¸ ì €ì¥"""
        checkpoint = {
            'epoch': epoch,
            'model_state_dict': self.model.state_dict(),
            'optimizer_state_dict': self.optimizer.state_dict(),
            'scheduler_state_dict': self.scheduler.state_dict() if self.scheduler else None,
            'best_val_loss': self.best_val_loss,
            'best_val_acc': self.best_val_acc,
            'config': self.config,
            'train_losses': self.train_losses,
            'val_losses': self.val_losses,
            'train_accuracies': self.train_accuracies,
            'val_accuracies': self.val_accuracies
        }
        
        # ìµœì‹  ì²´í¬í¬ì¸íŠ¸ ì €ì¥
        checkpoint_path = os.path.join(self.checkpoint_dir, 'latest_checkpoint.pth')
        torch.save(checkpoint, checkpoint_path)
        
        # ìµœê³  ëª¨ë¸ ì €ì¥
        if is_best:
            best_path = os.path.join(self.model_dir, 'best_model.pth')
            torch.save(checkpoint, best_path)
            logger.info(f"ìµœê³  ëª¨ë¸ ì €ì¥: {best_path}")
    
    def save_training_results(self, summary: Dict[str, Any]):
        """í•™ìŠµ ê²°ê³¼ ì €ì¥"""
        results = {
            'training_summary': summary,
            'train_losses': self.train_losses,
            'val_losses': self.val_losses,
            'train_accuracies': self.train_accuracies,
            'val_accuracies': self.val_accuracies,
            'learning_rates': self.learning_rates,
            'config': self.config
        }
        
        results_path = os.path.join(self.log_dir, 'training_results.json')
        with open(results_path, 'w', encoding='utf-8') as f:
            json.dump(results, f, indent=2, ensure_ascii=False)
        
        logger.info(f"í•™ìŠµ ê²°ê³¼ ì €ì¥: {results_path}")
    
    def plot_training_curves(self):
        """í•™ìŠµ ê³¡ì„  ê·¸ë˜í”„ ìƒì„±"""
        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))
        
        epochs = range(1, len(self.train_losses) + 1)
        
        # ì†ì‹¤ ê³¡ì„ 
        ax1.plot(epochs, self.train_losses, 'b-', label='Train Loss')
        ax1.plot(epochs, self.val_losses, 'r-', label='Val Loss')
        ax1.set_title('Training and Validation Loss')
        ax1.set_xlabel('Epoch')
        ax1.set_ylabel('Loss')
        ax1.legend()
        ax1.grid(True)
        
        # ì •í™•ë„ ê³¡ì„ 
        ax2.plot(epochs, self.train_accuracies, 'b-', label='Train Acc')
        ax2.plot(epochs, self.val_accuracies, 'r-', label='Val Acc')
        ax2.set_title('Training and Validation Accuracy')
        ax2.set_xlabel('Epoch')
        ax2.set_ylabel('Accuracy (%)')
        ax2.legend()
        ax2.grid(True)
        
        # í•™ìŠµë¥  ê³¡ì„ 
        ax3.plot(epochs, self.learning_rates, 'g-')
        ax3.set_title('Learning Rate Schedule')
        ax3.set_xlabel('Epoch')
        ax3.set_ylabel('Learning Rate')
        ax3.set_yscale('log')
        ax3.grid(True)
        
        # ê²€ì¦ ì†ì‹¤ vs ì •í™•ë„
        ax4.scatter(self.val_losses, self.val_accuracies, alpha=0.6)
        ax4.set_title('Validation Loss vs Accuracy')
        ax4.set_xlabel('Validation Loss')
        ax4.set_ylabel('Validation Accuracy (%)')
        ax4.grid(True)
        
        plt.tight_layout()
        
        # ê·¸ë˜í”„ ì €ì¥
        plot_path = os.path.join(self.log_dir, 'training_curves.png')
        plt.savefig(plot_path, dpi=300, bbox_inches='tight')
        plt.close()
        
        logger.info(f"í•™ìŠµ ê³¡ì„  ì €ì¥: {plot_path}")
    
    def load_checkpoint(self, checkpoint_path: str) -> int:
        """ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ"""
        checkpoint = torch.load(checkpoint_path, map_location=self.device)
        
        self.model.load_state_dict(checkpoint['model_state_dict'])
        self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
        
        if self.scheduler and checkpoint['scheduler_state_dict']:
            self.scheduler.load_state_dict(checkpoint['scheduler_state_dict'])
        
        self.best_val_loss = checkpoint['best_val_loss']
        self.best_val_acc = checkpoint['best_val_acc']
        self.train_losses = checkpoint.get('train_losses', [])
        self.val_losses = checkpoint.get('val_losses', [])
        self.train_accuracies = checkpoint.get('train_accuracies', [])
        self.val_accuracies = checkpoint.get('val_accuracies', [])
        
        epoch = checkpoint['epoch']
        logger.info(f"ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ: ì—í¬í¬ {epoch}")
        
        return epoch