# image_classification/dataset.py
"""
ì´ë¯¸ì§€ ë¶„ë¥˜ë¥¼ ìœ„í•œ ë°ì´í„°ì…‹ ë° ì „ì²˜ë¦¬

ImageDataset: CSV ê¸°ë°˜ ì´ë¯¸ì§€ ë°ì´í„°ì…‹ í´ë˜ìŠ¤
- ì´ë¯¸ì§€ ë¡œë“œ ë° ì „ì²˜ë¦¬
- ì¹´í…Œê³ ë¦¬ ë ˆì´ë¸” ì¸ì½”ë”©
- ë°ì´í„° ì¦ê°•

ImageTransforms: ì´ë¯¸ì§€ ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸
- í•™ìŠµ/ê²€ì¦/í…ŒìŠ¤íŠ¸ìš© ë³€í™˜
- ì •ê·œí™” ë° í¬ê¸° ì¡°ì •
"""

import torch
from torch.utils.data import Dataset, DataLoader
import torchvision.transforms as transforms
from PIL import Image
import pandas as pd
import numpy as np
import os
from typing import Dict, Any, Tuple, Optional, List
import logging
from sklearn.preprocessing import LabelEncoder
import requests
from io import BytesIO
import warnings

logger = logging.getLogger(__name__)
warnings.filterwarnings('ignore', category=UserWarning)

class ImageDataset(Dataset):
    """
    CSV ê¸°ë°˜ ì´ë¯¸ì§€ ë°ì´í„°ì…‹
    
    CSV íŒŒì¼ì˜ ì´ë¯¸ì§€ ê²½ë¡œì™€ ì¹´í…Œê³ ë¦¬ ì •ë³´ë¥¼ ì‚¬ìš©í•˜ì—¬
    ì´ë¯¸ì§€ë¥¼ ë¡œë“œí•˜ê³  ì „ì²˜ë¦¬í•˜ëŠ” ë°ì´í„°ì…‹
    """
    
    def __init__(self, 
                 data: pd.DataFrame,
                 transform: Optional[transforms.Compose] = None,
                 label_encoder: Optional[LabelEncoder] = None,
                 base_image_path: str = "",
                 target_column: str = 'is_text_tag',
                 is_remote: bool = False):
        """
        Args:
            data: ì´ë¯¸ì§€ ì •ë³´ê°€ ë‹´ê¸´ DataFrame
            transform: ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ë³€í™˜
            label_encoder: ë ˆì´ë¸” ì¸ì½”ë”
            base_image_path: ì´ë¯¸ì§€ ê¸°ë³¸ ê²½ë¡œ
            target_column: íƒ€ê²Ÿ ì»¬ëŸ¼ëª… ('is_text_tag')
            is_remote: ì›ê²© ì´ë¯¸ì§€ ì—¬ë¶€ (URLë¡œ ì ‘ê·¼)
        """
        self.data = data.copy()
        self.transform = transform
        self.base_image_path = base_image_path
        self.target_column = target_column
        self.is_remote = is_remote
        
        # ìœ íš¨í•œ ì´ë¯¸ì§€ê°€ ìˆëŠ” ë°ì´í„°ë§Œ í•„í„°ë§
        self.data = self._filter_valid_images()
        
        # ë ˆì´ë¸” ì¸ì½”ë” ì„¤ì •
        if label_encoder is None:
            self.label_encoder = LabelEncoder()
            # is_text_tagê°€ ì´ë¯¸ ì •ìˆ˜í˜•ì¸ ê²½ìš° ì§ì ‘ ì‚¬ìš©
            if target_column == 'is_text_tag':
                self.labels = self.data[target_column].values
                # 0ê³¼ 1ë§Œ ìˆëŠ”ì§€ í™•ì¸
                unique_labels = np.unique(self.labels)
                self.label_encoder.classes_ = np.array(['others', 'tag_images'])
            else:
                self.labels = self.label_encoder.fit_transform(self.data[target_column])
        else:
            self.label_encoder = label_encoder
            if target_column == 'is_text_tag':
                self.labels = self.data[target_column].values
            else:
                self.labels = self.label_encoder.transform(self.data[target_column])
        
        self.num_classes = len(self.label_encoder.classes_)
        
        logger.info(f"ë°ì´í„°ì…‹ ì´ˆê¸°í™” ì™„ë£Œ: {len(self.data)}ê°œ ìƒ˜í”Œ, {self.num_classes}ê°œ í´ë˜ìŠ¤")
        self._print_class_distribution()
    
    def _filter_valid_images(self) -> pd.DataFrame:
        """ìœ íš¨í•œ ì´ë¯¸ì§€ê°€ ìˆëŠ” ë°ì´í„°ë§Œ í•„í„°ë§"""
        # image_pathê°€ ìˆëŠ” ë°ì´í„°ë§Œ ì„ íƒ (ìƒˆë¡œìš´ ë°ì´í„° êµ¬ì¡°)
        valid_mask = (self.data['image_path'].notna() & 
                     (self.data['image_path'] != '') & 
                     (self.data['image_path'].astype(str).str.strip() != ''))
        
        filtered_data = self.data[valid_mask].copy()
        
        if len(filtered_data) == 0:
            raise ValueError("ìœ íš¨í•œ ì´ë¯¸ì§€ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        
        logger.info(f"ìœ íš¨í•œ ì´ë¯¸ì§€ ë°ì´í„°: {len(filtered_data)}/{len(self.data)}ê°œ")
        return filtered_data
    
    def _print_class_distribution(self):
        """í´ë˜ìŠ¤ ë¶„í¬ ì¶œë ¥"""
        if self.target_column == 'is_text_tag':
            # ì´ì§„ ë¶„ë¥˜ìš© íŠ¹ë³„ ì²˜ë¦¬
            class_counts = pd.Series(self.labels).value_counts().sort_index()
            print("ğŸ“Š í´ë˜ìŠ¤ ë¶„í¬:")
            print(f"  0 (others): {class_counts.get(0, 0):,}ê°œ")
            print(f"  1 (tag_images): {class_counts.get(1, 0):,}ê°œ")
        else:
            class_counts = pd.Series(self.labels).value_counts().sort_index()
            print("ğŸ“Š í´ë˜ìŠ¤ ë¶„í¬:")
            for class_idx, count in class_counts.items():
                class_name = self.label_encoder.classes_[class_idx]
                print(f"  {class_idx}: {class_name} - {count:,}ê°œ")
    
    def __len__(self) -> int:
        return len(self.data)
    
    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, int]:
        """
        ë°ì´í„°ì…‹ì—ì„œ í•˜ë‚˜ì˜ ìƒ˜í”Œ ë°˜í™˜
        
        Returns:
            (image_tensor, label): ì „ì²˜ë¦¬ëœ ì´ë¯¸ì§€ì™€ ë ˆì´ë¸”
        """
        try:
            # ì´ë¯¸ì§€ ë¡œë“œ
            image = self._load_image(idx)
            
            # ë³€í™˜ ì ìš©
            if self.transform:
                image = self.transform(image)
            
            # ë ˆì´ë¸”
            label = self.labels[idx]
            
            return image, label
            
        except Exception as e:
            logger.warning(f"ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨ (idx={idx}): {e}")
            # ê¸°ë³¸ ì´ë¯¸ì§€ ë°˜í™˜ (ê²€ì€ìƒ‰ ì´ë¯¸ì§€)
            default_image = Image.new('RGB', (224, 224), color='black')
            if self.transform:
                default_image = self.transform(default_image)
            return default_image, self.labels[idx]
    
    def _load_image(self, idx: int) -> Image.Image:
        """ì´ë¯¸ì§€ ë¡œë“œ"""
        row = self.data.iloc[idx]
        image_path = str(row['image_path']).strip()
        
        # ì´ë¯¸ì§€ ê²½ë¡œ êµ¬ì„± (CloudFront URL í¬í•¨)
        full_image_url = self._build_image_path(image_path)
        
        try:
            if full_image_url.startswith(('http://', 'https://')):
                # ì›ê²© ì´ë¯¸ì§€ ë¡œë“œ (CloudFront ë“±)
                response = requests.get(full_image_url, timeout=10)
                response.raise_for_status()
                image = Image.open(BytesIO(response.content))
            else:
                # ë¡œì»¬ ì´ë¯¸ì§€ ë¡œë“œ
                if not os.path.exists(full_image_url):
                    raise FileNotFoundError(f"ì´ë¯¸ì§€ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {full_image_url}")
                
                image = Image.open(full_image_url)
            
            # RGBë¡œ ë³€í™˜
            if image.mode != 'RGB':
                image = image.convert('RGB')
            
            return image
            
        except Exception as e:
            logger.warning(f"ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨: {full_image_url} - {e}")
            # ê¸°ë³¸ ê²€ì€ìƒ‰ ì´ë¯¸ì§€ ë°˜í™˜
            return Image.new('RGB', (224, 224), color='black')
    
    def _build_image_path(self, image_path: str) -> str:
        """ì´ë¯¸ì§€ ê²½ë¡œ êµ¬ì„± (CloudFront URL í¬í•¨)"""
        if image_path.startswith(('http://', 'https://')):
            # ì´ë¯¸ ì™„ì „í•œ URLì¸ ê²½ìš°
            return image_path
        elif self.base_image_path:
            # ë¡œì»¬ ê¸°ë³¸ ê²½ë¡œê°€ ìˆëŠ” ê²½ìš°
            return os.path.join(self.base_image_path, image_path)
        else:
            # CloudFront URL êµ¬ì„±
            from utils.env_loader import get_env_var
            cloudfront_domain = get_env_var('S3_CLOUDFRONT_DOMAIN')
            return f"https://{cloudfront_domain}/{image_path}"
    
    def get_class_names(self) -> List[str]:
        """í´ë˜ìŠ¤ ì´ë¦„ ëª©ë¡ ë°˜í™˜"""
        return list(self.label_encoder.classes_)
    
    def get_class_weights(self) -> torch.Tensor:
        """í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ê³„ì‚° (ë¶ˆê· í˜• ë°ì´í„° ì²˜ë¦¬ìš©)"""
        class_counts = np.bincount(self.labels)
        total_samples = len(self.labels)
        weights = total_samples / (len(class_counts) * class_counts)
        return torch.FloatTensor(weights)


class ImageTransforms:
    """ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ë³€í™˜ í´ë˜ìŠ¤"""
    
    @staticmethod
    def get_train_transforms(image_size: int = 224, augmentation_strength: str = 'medium') -> transforms.Compose:
        """í•™ìŠµìš© ì´ë¯¸ì§€ ë³€í™˜ (ë°ì´í„° ì¦ê°• í¬í•¨)"""
        transform_list = [
            transforms.Resize((image_size + 32, image_size + 32)),
            transforms.RandomCrop(image_size),
            transforms.RandomHorizontalFlip(p=0.5),
        ]
        
        if augmentation_strength in ['medium', 'strong']:
            transform_list.extend([
                transforms.RandomRotation(degrees=10),
                transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),
            ])
        
        if augmentation_strength == 'strong':
            transform_list.extend([
                transforms.RandomAffine(degrees=15, translate=(0.1, 0.1), scale=(0.9, 1.1)),
                transforms.RandomPerspective(distortion_scale=0.2, p=0.3),
            ])
        
        transform_list.extend([
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
        ])
        
        return transforms.Compose(transform_list)
    
    @staticmethod
    def get_val_transforms(image_size: int = 224) -> transforms.Compose:
        """ê²€ì¦/í…ŒìŠ¤íŠ¸ìš© ì´ë¯¸ì§€ ë³€í™˜"""
        return transforms.Compose([
            transforms.Resize((image_size, image_size)),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
        ])


def create_data_loaders(train_df: pd.DataFrame, 
                       val_df: pd.DataFrame, 
                       test_df: pd.DataFrame,
                       config: Dict[str, Any]) -> Tuple[DataLoader, DataLoader, DataLoader, LabelEncoder]:
    """
    ë°ì´í„° ë¡œë” ìƒì„±
    
    Args:
        train_df: í•™ìŠµ ë°ì´í„°
        val_df: ê²€ì¦ ë°ì´í„°  
        test_df: í…ŒìŠ¤íŠ¸ ë°ì´í„°
        config: ì„¤ì • ë”•ì…”ë„ˆë¦¬
        
    Returns:
        (train_loader, val_loader, test_loader, label_encoder)
    """
    # ì„¤ì • ì¶”ì¶œ
    batch_size = config.get('training', {}).get('batch_size', 32)
    image_size = config.get('augmentation', {}).get('image_size', 224)
    augmentation_strength = config.get('augmentation', {}).get('strength', 'medium')
    num_workers = config.get('system', {}).get('num_workers', 4)
    pin_memory = config.get('system', {}).get('pin_memory', True)
    base_image_path = config.get('data', {}).get('base_image_path', '')
    target_column = config.get('data', {}).get('target_column', 'is_text_tag')
    is_remote = config.get('data', {}).get('is_remote', False)
    
    # ë³€í™˜ ìƒì„±
    train_transforms = ImageTransforms.get_train_transforms(image_size, augmentation_strength)
    val_transforms = ImageTransforms.get_val_transforms(image_size)
    
    # ë ˆì´ë¸” ì¸ì½”ë” ìƒì„±
    if target_column == 'is_text_tag':
        # ì´ì§„ ë¶„ë¥˜ì˜ ê²½ìš° ë¯¸ë¦¬ ì •ì˜ëœ í´ë˜ìŠ¤ ì‚¬ìš©
        label_encoder = LabelEncoder()
        label_encoder.classes_ = np.array(['others', 'tag_images'])
    else:
        # ë‹¤ì¤‘ í´ë˜ìŠ¤ ë¶„ë¥˜ì˜ ê²½ìš° ì „ì²´ ë°ì´í„°ì˜ ì¹´í…Œê³ ë¦¬ ê¸°ì¤€
        all_categories = pd.concat([train_df, val_df, test_df])[target_column].unique()
        label_encoder = LabelEncoder()
        label_encoder.fit(all_categories)
    
    # ë°ì´í„°ì…‹ ìƒì„±
    train_dataset = ImageDataset(
        train_df, train_transforms, label_encoder, 
        base_image_path, target_column, is_remote
    )
    val_dataset = ImageDataset(
        val_df, val_transforms, label_encoder, 
        base_image_path, target_column, is_remote
    )
    test_dataset = ImageDataset(
        test_df, val_transforms, label_encoder, 
        base_image_path, target_column, is_remote
    )
    
    # ë°ì´í„° ë¡œë” ìƒì„± (BatchNorm ì—ëŸ¬ ë°©ì§€ë¥¼ ìœ„í•´ drop_last=True ì¶”ê°€)
    train_loader = DataLoader(
        train_dataset, batch_size=batch_size, shuffle=True,
        num_workers=num_workers, pin_memory=pin_memory, drop_last=True
    )
    val_loader = DataLoader(
        val_dataset, batch_size=batch_size, shuffle=False,
        num_workers=num_workers, pin_memory=pin_memory, drop_last=True
    )
    test_loader = DataLoader(
        test_dataset, batch_size=batch_size, shuffle=False,
        num_workers=num_workers, pin_memory=pin_memory, drop_last=False
    )
    
    logger.info(f"ë°ì´í„° ë¡œë” ìƒì„± ì™„ë£Œ:")
    logger.info(f"  - í•™ìŠµ: {len(train_dataset)}ê°œ ìƒ˜í”Œ, {len(train_loader)}ê°œ ë°°ì¹˜")
    logger.info(f"  - ê²€ì¦: {len(val_dataset)}ê°œ ìƒ˜í”Œ, {len(val_loader)}ê°œ ë°°ì¹˜")
    logger.info(f"  - í…ŒìŠ¤íŠ¸: {len(test_dataset)}ê°œ ìƒ˜í”Œ, {len(test_loader)}ê°œ ë°°ì¹˜")
    
    return train_loader, val_loader, test_loader, label_encoder


def get_dataset_statistics(data_loader: DataLoader) -> Dict[str, Any]:
    """ë°ì´í„°ì…‹ í†µê³„ ì •ë³´ ê³„ì‚°"""
    dataset = data_loader.dataset
    
    # í´ë˜ìŠ¤ ë¶„í¬
    labels = [dataset[i][1] for i in range(len(dataset))]
    class_counts = np.bincount(labels)
    
    statistics = {
        'total_samples': len(dataset),
        'num_classes': dataset.num_classes,
        'class_names': dataset.get_class_names(),
        'class_counts': class_counts.tolist(),
        'class_distribution': {
            name: count for name, count in zip(dataset.get_class_names(), class_counts)
        },
        'batch_size': data_loader.batch_size,
        'num_batches': len(data_loader)
    }
    
    return statistics
