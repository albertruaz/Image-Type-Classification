#!/usr/bin/env python3
# main.py
"""
ì´ë¯¸ì§€ íƒ€ì… ë¶„ë¥˜ ë©”ì¸ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸

CSV íŒŒì¼ ê¸°ë°˜ ì´ë¯¸ì§€ ë¶„ë¥˜ ì‹œìŠ¤í…œì˜ ì „ì²´ íŒŒì´í”„ë¼ì¸ì„ ì‹¤í–‰:
1. CSV ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬
2. ë°ì´í„° ë¶„í•  (train/val/test)
3. ëª¨ë¸ ìƒì„± ë° í•™ìŠµ
4. í‰ê°€ ë° ê²°ê³¼ ì €ì¥

ì‚¬ìš©ë²•:
    python main.py                          # ê¸°ë³¸ ì„¤ì •ìœ¼ë¡œ ì‹¤í–‰
    python main.py --config custom.json    # ì»¤ìŠ¤í…€ ì„¤ì •ìœ¼ë¡œ ì‹¤í–‰
    python main.py --mode inference        # ì¶”ë¡  ëª¨ë“œ
    python main.py --quick-test             # ë¹ ë¥¸ í…ŒìŠ¤íŠ¸
"""

import argparse
import json
import os
import sys
import logging
from pathlib import Path
from datetime import datetime
import torch
import pandas as pd

from typing import Dict, Any, Tuple

try:
    import wandb
    WANDB_AVAILABLE = True
except ImportError:
    WANDB_AVAILABLE = False

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì¶”ê°€
project_root = Path(__file__).parent
sys.path.append(str(project_root))

from utils.config_manager import ConfigManager
from utils.device_manager import DeviceManager

from utils.logging_utils import setup_project_logging, log_execution_time, handle_exceptions
from utils.env_loader import load_env_once
from image_classification.cnn_model import create_image_classifier, print_model_summary
from image_classification.dataset import create_data_loaders, get_dataset_statistics
from image_classification.trainer import ImageClassifierTrainer
from image_classification.evaluator import ModelEvaluator

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ (í•œ ë²ˆë§Œ)
load_env_once()

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class ImageTypeClassificationPipeline:
    """ì´ë¯¸ì§€ íƒ€ì… ë¶„ë¥˜ íŒŒì´í”„ë¼ì¸ ë©”ì¸ í´ë˜ìŠ¤"""

    def __init__(self, config_path: str = "config.json"):
        """
        Args:
            config_path: ì„¤ì • íŒŒì¼ ê²½ë¡œ
        """
        self.config_path = config_path
        self.start_time = datetime.now()
        
        # ì„¤ì • ê´€ë¦¬ìë¥¼ í†µí•œ ì„¤ì • ë¡œë“œ ë° ê²€ì¦
        self.config_manager = ConfigManager(config_path)
        self.config = self.config_manager.get_config()
        
        # í´ë˜ìŠ¤ ì •ë³´ ì„¤ì • (configì—ì„œ ë¡œë“œ)
        self.CLASS_NAMES = self.config.get('data', {}).get('class_names', 
            ['care_label', 'detail_shot', 'full_shot', 'neck_label'])
        self.NUM_CLASSES = len(self.CLASS_NAMES)
        
        # ê³ ìœ  ì‹¤í–‰ ë””ë ‰í† ë¦¬ ìƒì„±
        base_results_dir = self.config.get('paths', {}).get('result_dir', 'results')
        
        # ê³ ìœ í•œ run í´ë” ìƒì„±
        import uuid
        timestamp = self.start_time.strftime("%Y%m%d_%H%M%S")
        unique_id = str(uuid.uuid4())[:8]  # 8ìë¦¬ ê³ ìœ  ID
        self.run_id = f"run_{timestamp}_{unique_id}"
        
        # run í´ë” ê²½ë¡œ ì„¤ì •
        run_dir = os.path.join(base_results_dir, self.run_id)
        self.run_paths = {
            'run_dir': run_dir,
            'result_dir': run_dir,
            'model_dir': os.path.join(run_dir, 'model'),
            'log_dir': os.path.join(run_dir, 'logs'),
            'checkpoint_dir': os.path.join(run_dir, 'checkpoints')
        }
        
        # í•„ìš”í•œ ë””ë ‰í† ë¦¬ë“¤ ìƒì„±
        for path in self.run_paths.values():
            os.makedirs(path, exist_ok=True)
        
        # ì„¤ì •ì˜ ê²½ë¡œë“¤ì„ ìƒˆë¡œìš´ êµ¬ì¡°ì— ë§ê²Œ ì—…ë°ì´íŠ¸
        self._update_config_paths()
        
        # ì‹¤í–‰ ì‹œì ì˜ ì„¤ì • ì €ì¥
        config_path = os.path.join(self.run_paths['run_dir'], 'config.json')
        with open(config_path, 'w', encoding='utf-8') as f:
            json.dump(self.config, f, indent=2, ensure_ascii=False)
        logger.info(f"ì‹¤í–‰ ì„¤ì • ì €ì¥: {config_path}")
        
        # í”„ë¡œì íŠ¸ ë¡œê¹… ì„¤ì • (ìƒˆë¡œìš´ log ë””ë ‰í† ë¦¬ ì‚¬ìš©)
        setup_project_logging(self.config)
        
        # ë””ë°”ì´ìŠ¤ ê´€ë¦¬ìë¥¼ í†µí•œ ë””ë°”ì´ìŠ¤ ì„¤ì •
        device_config = self.config.get('system', {}).get('device', 'auto')
        self.device = DeviceManager.get_device(device_config)
        
        logger.info("=" * 60)
        logger.info(f"ğŸš€ ìƒˆë¡œìš´ ì‹¤í–‰ ì‹œì‘ - ID: {self.run_id}")
        logger.info(f"ğŸ“ ì‹¤í–‰ ë””ë ‰í† ë¦¬: {self.run_paths['run_dir']}")
        logger.info(f"ğŸ’» ë””ë°”ì´ìŠ¤: {self.device}")
        logger.info("=" * 60)
        
        # ë””ë°”ì´ìŠ¤ ì •ë³´ ì¶œë ¥
        device_info = DeviceManager.get_device_info()
        logger.info(f"ë””ë°”ì´ìŠ¤ ì •ë³´: {device_info['name']} ({device_info['memory_gb']})")
        
        # ì‹¤í–‰ ë©”íƒ€ë°ì´í„° ìƒì„±
        metadata = {
            'run_id': self.run_id,
            'start_time': self.start_time.isoformat(),
            'config_file': self.config_path,
            'python_version': sys.version,
            'torch_version': torch.__version__,
            'device_info': DeviceManager.get_device_info()
        }
        metadata_path = os.path.join(self.run_paths['run_dir'], 'run_metadata.json')
        with open(metadata_path, 'w', encoding='utf-8') as f:
            json.dump(metadata, f, indent=2, ensure_ascii=False)
        logger.info(f"ì‹¤í–‰ ë©”íƒ€ë°ì´í„° ì €ì¥: {metadata_path}")
    
    def _update_config_paths(self):
        """ì„¤ì •ì˜ ê²½ë¡œë“¤ì„ ìƒˆë¡œìš´ ì‹¤í–‰ ë””ë ‰í† ë¦¬ êµ¬ì¡°ì— ë§ê²Œ ì—…ë°ì´íŠ¸"""
        paths_config = self.config.get('paths', {})
        
        # ê¸°ì¡´ ê²½ë¡œë¥¼ ìƒˆë¡œìš´ êµ¬ì¡°ë¡œ ë§¤í•‘
        paths_config['result_dir'] = self.run_paths['result_dir']
        paths_config['model_dir'] = self.run_paths['model_dir']
        paths_config['log_dir'] = self.run_paths['log_dir']
        paths_config['checkpoint_dir'] = self.run_paths['checkpoint_dir']
        
        logger.info(f"ê²½ë¡œ ì—…ë°ì´íŠ¸ ì™„ë£Œ:")
        logger.info(f"  ê²°ê³¼: {self.run_paths['result_dir']}")
        logger.info(f"  ëª¨ë¸: {self.run_paths['model_dir']}")
        logger.info(f"  ë¡œê·¸: {self.run_paths['log_dir']}")

    @log_execution_time()
    @handle_exceptions()
    def load_data(self, data_dir: str = "data") -> Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]:
        """ë¯¸ë¦¬ ë¶„í• ëœ ë°ì´í„° ë¡œë“œ"""
        logger.info("=" * 60)
        logger.info("ğŸ“‚ ë¯¸ë¦¬ ë¶„í• ëœ ë°ì´í„° ë¡œë“œ")
        logger.info("=" * 60)
        
        # ë¶„í• ëœ ë°ì´í„° íŒŒì¼ ê²½ë¡œ
        train_path = os.path.join(data_dir, 'train_data.csv')
        val_path = os.path.join(data_dir, 'validation_data.csv')
        test_path = os.path.join(data_dir, 'test_data.csv')
        
        # íŒŒì¼ ì¡´ì¬ í™•ì¸
        missing_files = []
        for name, path in [('train', train_path), ('validation', val_path), ('test', test_path)]:
            if not os.path.exists(path):
                missing_files.append(f"{name}: {path}")
        
        if missing_files:
            logger.error("ë‹¤ìŒ ë¶„í• ëœ ë°ì´í„° íŒŒì¼ë“¤ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤:")
            for missing in missing_files:
                logger.error(f"  - {missing}")
            logger.error("ë¨¼ì € 'python divide_data.py'ë¥¼ ì‹¤í–‰í•˜ì—¬ ë°ì´í„°ë¥¼ ë¶„í• í•˜ì„¸ìš”.")
            raise FileNotFoundError("ë¶„í• ëœ ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        
        # ë°ì´í„° ë¡œë“œ ë° ì…”í”Œë§
        logger.info(f"Train ë°ì´í„° ë¡œë“œ: {train_path}")
        train_df = pd.read_csv(train_path, encoding='utf-8')
        # Train ë°ì´í„° ì…”í”Œë§ (ê°™ì€ ì œí’ˆ ì´ë¯¸ì§€ë“¤ì´ ì—°ì†ìœ¼ë¡œ ë‚˜ì˜¤ëŠ” ê²ƒ ë°©ì§€)
        train_df = train_df.sample(frac=1, random_state=42).reset_index(drop=True)
        logger.info("Train ë°ì´í„° ì…”í”Œë§ ì™„ë£Œ (ì œí’ˆë³„ ìˆœì„œ ì œê±°)")
        
        logger.info(f"Validation ë°ì´í„° ë¡œë“œ: {val_path}")
        val_df = pd.read_csv(val_path, encoding='utf-8')
        # Validationì€ ì¬í˜„ì„±ì„ ìœ„í•´ ì…”í”Œë§í•˜ì§€ ì•ŠìŒ
        
        logger.info(f"Test ë°ì´í„° ë¡œë“œ: {test_path}")
        test_df = pd.read_csv(test_path, encoding='utf-8')
        # Testë„ ì¬í˜„ì„±ì„ ìœ„í•´ ì…”í”Œë§í•˜ì§€ ì•ŠìŒ
        
        # ë°ì´í„° ìš”ì•½ ì¶œë ¥ (4í´ë˜ìŠ¤ ë¶„ë¥˜)
        total_samples = len(train_df) + len(val_df) + len(test_df)
        
        # ì´ë¯¸ì§€ íƒ€ì… ë¶„í¬ í™•ì¸
        train_type_dist = train_df['image_type'].value_counts()
        val_type_dist = val_df['image_type'].value_counts()
        test_type_dist = test_df['image_type'].value_counts()
        
        logger.info(f"ë°ì´í„° ìš”ì•½ (4í´ë˜ìŠ¤ ì´ë¯¸ì§€ íƒ€ì… ë¶„ë¥˜):")
        logger.info(f"  ì „ì²´: {total_samples:,}ê°œ ì´ë¯¸ì§€")
        logger.info(f"  Train: {len(train_df):,}ê°œ ({len(train_df)/total_samples*100:.1f}%)")
        logger.info(f"  Validation: {len(val_df):,}ê°œ ({len(val_df)/total_samples*100:.1f}%)")
        logger.info(f"  Test: {len(test_df):,}ê°œ ({len(test_df)/total_samples*100:.1f}%)")
        logger.info(f"  í´ë˜ìŠ¤: {', '.join(self.CLASS_NAMES)}")
        
        # ì´ë¯¸ì§€ íƒ€ì… ë¶„í¬ ì¶œë ¥
        logger.info(f"ì´ë¯¸ì§€ íƒ€ì… ë¶„í¬:")
        for img_type in sorted(train_type_dist.index):
            logger.info(f"  {img_type}: Train {train_type_dist.get(img_type, 0):,}, Val {val_type_dist.get(img_type, 0):,}, Test {test_type_dist.get(img_type, 0):,}")
        
        # ì œí’ˆ ì •ë³´
        train_products = train_df['product_id'].nunique()
        val_products = val_df['product_id'].nunique()
        test_products = test_df['product_id'].nunique()
        total_products = train_products + val_products + test_products
        
        logger.info(f"ì œí’ˆ ë¶„í• :")
        logger.info(f"  ì „ì²´: {total_products:,}ê°œ ì œí’ˆ")
        logger.info(f"  Train: {train_products:,}ê°œ, Val: {val_products:,}ê°œ, Test: {test_products:,}ê°œ")
        
        # ë¶„í•  ìš”ì•½ íŒŒì¼ì´ ìˆìœ¼ë©´ ì •ë³´ ì¶œë ¥
        summary_path = os.path.join(data_dir, 'data_split_summary.json')
        if os.path.exists(summary_path):
            try:
                import json
                with open(summary_path, 'r', encoding='utf-8') as f:
                    summary = json.load(f)
                    logger.info(f"ë°ì´í„° ë¶„í•  ì •ë³´: {summary['split_info']['created_at']}ì— ìƒì„±")
                    logger.info(f"ëœë¤ ì‹œë“œ: {summary['split_info']['random_state']}")
            except Exception as e:
                logger.warning(f"ë¶„í•  ìš”ì•½ íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {e}")
        
        return train_df, val_df, test_df
    
    @log_execution_time()
    @handle_exceptions()
    def create_data_loaders(self, train_df: pd.DataFrame, val_df: pd.DataFrame, 
                          test_df: pd.DataFrame) -> Tuple:
        """ë°ì´í„° ë¡œë” ìƒì„±"""
        logger.info("=" * 60)
        logger.info("ğŸ”„ ë°ì´í„° ë¡œë” ìƒì„±")
        logger.info("=" * 60)
        
        train_loader, val_loader, test_loader, label_encoder = create_data_loaders(
            train_df, val_df, test_df, self.config
        )
        
        # ë°ì´í„°ì…‹ í†µê³„
        train_stats = get_dataset_statistics(train_loader)
        logger.info(f"í•™ìŠµ ë°ì´í„°ì…‹ í†µê³„: {train_stats}")
        
        return train_loader, val_loader, test_loader, label_encoder
    
    def create_model(self, num_classes: int):
        """ëª¨ë¸ ìƒì„±"""
        logger.info("=" * 60)
        logger.info("ğŸ§  ëª¨ë¸ ìƒì„±")
        logger.info("=" * 60)
        
        model = create_image_classifier(self.config, num_classes)
        
        # ëª¨ë¸ ìš”ì•½ ì¶œë ¥
        print_model_summary(model)
        
        return model
    
    @log_execution_time()
    @handle_exceptions()
    def train_model(self, model, train_loader, val_loader) -> Dict[str, Any]:
        """ëª¨ë¸ í•™ìŠµ (í–¥ìƒëœ íŠ¸ë ˆì´ë„ˆ ì‚¬ìš©)"""
        logger.info("=" * 60)
        logger.info("ğŸ‹ï¸ í–¥ìƒëœ ëª¨ë¸ í•™ìŠµ ì‹œì‘")
        logger.info("=" * 60)
        
        # í–¥ìƒëœ íŠ¸ë ˆì´ë„ˆ ìƒì„±
        trainer = ImageClassifierTrainer(
            model=model,
            train_loader=train_loader,
            val_loader=val_loader,
            config=self.config,
            device=self.device
        )
        
        # í•™ìŠµ ì‹¤í–‰
        training_results = trainer.train()
        
        return training_results
    
    @log_execution_time()
    @handle_exceptions()
    def evaluate_model(self, model, test_loader, class_names: list) -> Dict[str, Any]:
        """ëª¨ë¸ í‰ê°€"""
        logger.info("=" * 60)
        logger.info("ğŸ“Š ëª¨ë¸ í‰ê°€")
        logger.info("=" * 60)
        
        # í‰ê°€ê¸° ìƒì„± (ìƒˆë¡œìš´ ê²°ê³¼ ë””ë ‰í† ë¦¬ ì‚¬ìš©)
        evaluator = ModelEvaluator(
            model=model,
            test_loader=test_loader,
            class_names=class_names,
            device=self.device,
            save_dir=self.run_paths['result_dir']
        )
        
        # í‰ê°€ ì‹¤í–‰
        evaluation_results = evaluator.evaluate(save_results=True)
        
        return evaluation_results
    
    def run_training_pipeline(self) -> Dict[str, Any]:
        """ì „ì²´ í•™ìŠµ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""
        logger.info("ğŸš€ ì´ë¯¸ì§€ íƒ€ì… ë¶„ë¥˜ í•™ìŠµ íŒŒì´í”„ë¼ì¸ ì‹œì‘")
        
        # wandb ì´ˆê¸°í™”
        wandb_run = None
        if self.config.get('logging', {}).get('use_wandb', False) and WANDB_AVAILABLE:
            try:
                wandb_run = wandb.init(
                    project=self.config.get('logging', {}).get('wandb_project', 'image-classification'),
                    entity=self.config.get('logging', {}).get('wandb_entity', None),
                    config=self.config,
                    name=f"enhanced_{self.run_id}",
                    tags=['image-classification', 'pytorch', 'enhanced', 'discriminative-lr', 'ema']
                )
                logger.info(f"wandb ì‹¤í–‰ ì‹œì‘: {wandb.run.url}")
            except Exception as e:
                logger.warning(f"wandb ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
                wandb_run = None
        
        try:
            # 1. ë¯¸ë¦¬ ë¶„í• ëœ ë°ì´í„° ë¡œë“œ
            train_df, val_df, test_df = self.load_data()
            
            # 2. ë°ì´í„° ë¡œë” ìƒì„±
            train_loader, val_loader, test_loader, label_encoder = self.create_data_loaders(
                train_df, val_df, test_df
            )
            
            # 3. ëª¨ë¸ ìƒì„± (ì´ì§„ ë¶„ë¥˜)
            model = self.create_model(self.NUM_CLASSES)
            
            # ëª¨ë¸ ì •ë³´ë¥¼ ë©”íƒ€ë°ì´í„°ì— ì¶”ê°€
            model_info = {
                'backbone': self.config.get('model', {}).get('backbone', 'unknown'),
                'num_classes': self.NUM_CLASSES,
                'class_names': self.CLASS_NAMES,
                'total_params': sum(p.numel() for p in model.parameters()),
                'trainable_params': sum(p.numel() for p in model.parameters() if p.requires_grad)
            }
            
            # 4. ëª¨ë¸ í•™ìŠµ (í–¥ìƒëœ íŠ¸ë ˆì´ë„ˆ)
            training_results = self.train_model(model, train_loader, val_loader)
            
            # 5. ëª¨ë¸ í‰ê°€
            evaluation_results = self.evaluate_model(model, test_loader, self.CLASS_NAMES)
            
            # ìµœì¢… ê²°ê³¼ ìš”ì•½
            end_time = datetime.now()
            total_time = (end_time - self.start_time).total_seconds()
            
            final_results = {
                'run_info': {
                    'run_id': self.run_id,
                    'start_time': self.start_time.isoformat(),
                'end_time': end_time.isoformat(),
                'total_time_seconds': total_time,
                    'run_directory': self.run_paths['run_dir']
                },
                'config': self.config,
                'data_summary': {
                    'train_samples': len(train_df),
                    'val_samples': len(val_df),
                    'test_samples': len(test_df),
                    'num_classes': self.NUM_CLASSES,
                    'class_names': self.CLASS_NAMES
                },
                'model_info': model_info,
                'training_results': training_results,
                'evaluation_results': evaluation_results,
                'enhancements_used': {
                    'discriminative_lr': True,
                    'label_smoothing': self.config.get('training', {}).get('label_smoothing', 0) > 0,
                    'ema': self.config.get('training', {}).get('use_ema', False),
                    'warmup': self.config.get('training', {}).get('warmup_epochs', 0) > 0,
                    'mixed_precision': self.config.get('system', {}).get('mixed_precision', False)
                }
            }
            
            # ìµœì¢… ê²°ê³¼ ì €ì¥
            self._save_final_results(final_results)
            
            # wandb ìµœì¢… ê²°ê³¼ ë¡œê¹…
            if wandb_run:
                try:
                    wandb.log({
                        'final/total_time_seconds': total_time,
                        'final/best_val_accuracy': training_results['best_val_accuracy'],
                        'final/test_accuracy': evaluation_results['metrics']['accuracy'],
                        'final/num_classes': self.NUM_CLASSES,
                        'final/train_samples': len(train_df),
                        'final/val_samples': len(val_df),
                        'final/test_samples': len(test_df),
                        'final/label_smoothing_used': final_results['enhancements_used']['label_smoothing'],
                        'final/ema_used': final_results['enhancements_used']['ema'],
                        'final/run_id': self.run_id
                    })
                    # í•™ìŠµ ê³¡ì„  ì´ë¯¸ì§€ê°€ ìˆë‹¤ë©´ wandbì— ì—…ë¡œë“œ
                    curve_path = os.path.join(self.run_paths['log_dir'], 'training_curves.png')
                    if os.path.exists(curve_path):
                        wandb.log({"training_curves": wandb.Image(curve_path)})
                except Exception as e:
                    logger.warning(f"wandb ìµœì¢… ë¡œê¹… ì‹¤íŒ¨: {e}")
            
            logger.info("=" * 60)
            logger.info("âœ… í–¥ìƒëœ íŒŒì´í”„ë¼ì¸ ì™„ë£Œ")
            logger.info(f"ğŸ”– ì‹¤í–‰ ID: {self.run_id}")
            logger.info(f"ğŸ“ ê²°ê³¼ í´ë”: {self.run_paths['run_dir']}")
            logger.info(f"â±ï¸ ì´ ì‹¤í–‰ ì‹œê°„: {total_time:.1f}ì´ˆ")
            logger.info(f"ğŸ¯ ìµœê³  ê²€ì¦ ì •í™•ë„: {training_results['best_val_accuracy']:.2f}%")
            logger.info(f"ğŸ“Š í…ŒìŠ¤íŠ¸ ì •í™•ë„: {evaluation_results['metrics']['accuracy']:.4f}")
            logger.info("=" * 60)
            
            return final_results
            
        except Exception as e:
            logger.error(f"íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            raise
        finally:
            # wandb ì¢…ë£Œ
            if wandb_run:
                try:
                    wandb.finish()
                    logger.info("wandb ì‹¤í–‰ ì¢…ë£Œ")
                except Exception as e:
                    logger.warning(f"wandb ì¢…ë£Œ ì‹¤íŒ¨: {e}")
    
    # run_inference ë©”ì„œë“œ ì œê±°ë¨ (test.pyì—ì„œ ëŒ€ì²´)
 
    def _save_final_results(self, results: Dict[str, Any]):
        """ìµœì¢… ê²°ê³¼ ì €ì¥"""
        results_path = os.path.join(self.run_paths['result_dir'], 'final_results.json')
        
        with open(results_path, 'w', encoding='utf-8') as f:
            json.dump(results, f, indent=2, ensure_ascii=False)
        
        logger.info(f"ìµœì¢… ê²°ê³¼ ì €ì¥: {results_path}")


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(description='í–¥ìƒëœ ì´ë¯¸ì§€ íƒ€ì… ë¶„ë¥˜ ì‹œìŠ¤í…œ (êµ¬ì¡°í™”ëœ ê²°ê³¼ ì €ì¥)')
    parser.add_argument('--config', type=str, default='config.json',
                       help='ì„¤ì • íŒŒì¼ ê²½ë¡œ (ê¸°ë³¸ê°’: config.json)')
    parser.add_argument('--quick-test', action='store_true',
                       help='ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ (ì ì€ ì—í¬í¬)')
    
    args = parser.parse_args()

    try:
        # íŒŒì´í”„ë¼ì¸ ìƒì„±
        pipeline = ImageTypeClassificationPipeline(config_path=args.config)
        
        # ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ ì„¤ì •
        if args.quick_test:
            pipeline.config['training']['epochs'] = 5
            pipeline.config['training']['patience'] = 3
            pipeline.config['model']['freeze_backbone_epochs'] = 2
            logger.info("ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ ëª¨ë“œ: ì—í¬í¬ ìˆ˜ ì¡°ì •")
        
        # í•™ìŠµ ì‹¤í–‰
        results = pipeline.run_training_pipeline()
        print(f"\nğŸ‰ í–¥ìƒëœ í•™ìŠµ ì™„ë£Œ!")
        print(f"ğŸ“ ê²°ê³¼ í´ë”: {pipeline.run_paths['run_dir']}")
        print(f"ğŸ”– ì‹¤í–‰ ID: {pipeline.run_id}")
        print(f"ğŸ“Š ìµœì¢… ì •í™•ë„: {results['evaluation_results']['metrics']['accuracy']:.4f}")
        
    except KeyboardInterrupt:
        logger.info("ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë¨")
        sys.exit(1)
    except Exception as e:
        logger.error(f"ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()
