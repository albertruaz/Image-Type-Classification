#!/usr/bin/env python3
# test.py
"""
ì´ë¯¸ì§€ íƒ€ì… ë¶„ë¥˜ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸

ê¸°ì¡´ main.pyì˜ inference ê¸°ëŠ¥ê³¼ ë™ì¼í•˜ì§€ë§Œ test_result í´ë”ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.

ì‚¬ìš©ë²•:
    python test.py --model-path <ëª¨ë¸ê²½ë¡œ>                    # ê¸°ë³¸ ì¶”ë¡ 
    python test.py --model-path <ëª¨ë¸ê²½ë¡œ> --image-path <ì´ë¯¸ì§€ê²½ë¡œ>  # ë‹¨ì¼ ì´ë¯¸ì§€
    python test.py --model-path <ëª¨ë¸ê²½ë¡œ> --csv-path <CSVê²½ë¡œ>      # ë°°ì¹˜ ì¶”ë¡ 
"""

import argparse
import json
import os
import sys
import logging
from pathlib import Path
from datetime import datetime
import time
import torch
import pandas as pd
import numpy as np
from typing import Dict, Any, Tuple
import uuid

try:
    import wandb
    WANDB_AVAILABLE = True
except ImportError:
    WANDB_AVAILABLE = False

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì¶”ê°€
project_root = Path(__file__).parent
sys.path.append(str(project_root))

from utils.config_manager import ConfigManager
from utils.device_manager import DeviceManager
from utils.logging_utils import setup_project_logging, log_execution_time, handle_exceptions
from utils.env_loader import load_env_once
from database.csv_connector import CSVConnector
from image_classification.cnn_model import create_image_classifier, get_model_summary, print_model_summary
from image_classification.dataset import create_data_loaders, get_dataset_statistics
from image_classification.trainer import ImageClassifierTrainer
from image_classification.evaluator import ModelEvaluator

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ (í•œ ë²ˆë§Œ)
load_env_once()

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class ImageTypeClassificationTest:
    """ì´ë¯¸ì§€ íƒ€ì… ë¶„ë¥˜ í…ŒìŠ¤íŠ¸ í´ë˜ìŠ¤ (ë‹¨ìˆœ CSV ê²°ê³¼ ìƒì„±)"""
    
    def __init__(self, config_path: str = "config.json"):
        """
        Args:
            config_path: ì„¤ì • íŒŒì¼ ê²½ë¡œ
        """
        self.config_path = config_path
        self.start_time = datetime.now()
        
        # ì„¤ì • ê´€ë¦¬ìë¥¼ í†µí•œ ì„¤ì • ë¡œë“œ ë° ê²€ì¦
        self.config_manager = ConfigManager(config_path)
        self.config = self.config_manager.get_config()
        
        # ë””ë°”ì´ìŠ¤ ê´€ë¦¬ìë¥¼ í†µí•œ ë””ë°”ì´ìŠ¤ ì„¤ì •
        self.device = DeviceManager.get_device()
        
        # test_result í´ë”ì— run ë””ë ‰í† ë¦¬ ìƒì„±
        base_results_dir = "test_result"
        timestamp = self.start_time.strftime("%Y%m%d_%H%M%S")
        unique_id = str(uuid.uuid4())[:8]
        self.run_id = f"run_{timestamp}_{unique_id}"
        
        self.run_dir = os.path.join(base_results_dir, self.run_id)
        os.makedirs(self.run_dir, exist_ok=True)
        
        # ë””ë°”ì´ìŠ¤ ì •ë³´ ì¶œë ¥
        device_info = DeviceManager.get_device_info()
        logger.info(f"ë””ë°”ì´ìŠ¤ ì •ë³´: {device_info['name']} ({device_info['memory_gb']})")
        logger.info(f"ê²°ê³¼ ì €ì¥ í´ë”: {self.run_dir}")

    def run_inference(self, image_path: str = None, 
                      csv_path: str = None,
                      output_path: str = None,
                      model_path: str = None) -> str:
        """ì¶”ë¡  ì‹¤í–‰ - ë‹¨ìˆœ CSV ê²°ê³¼ ìƒì„±"""
        
        from image_classification.inference import ImageClassifierInference
        
        # ëª¨ë¸ ê²½ë¡œ í™•ì¸
        if not model_path or not os.path.exists(model_path):
            raise FileNotFoundError(f"ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {model_path}")
        
        logger.info(f"ì‚¬ìš©í•  ëª¨ë¸: {model_path}")
        
        # ì¶”ë¡ ê¸° ìƒì„±
        inference_config = self.config.get('inference', {})
        batch_size = inference_config.get('batch_size', 64)
        
        inference_engine = ImageClassifierInference(
            model_path=model_path,
            device=self.device
        )
        
        # ê²°ê³¼ë¥¼ ë‹´ì„ ë¦¬ìŠ¤íŠ¸
        all_results = []
        
        if image_path:
            # ë‹¨ì¼ ì´ë¯¸ì§€ ì˜ˆì¸¡
            logger.info(f"ë‹¨ì¼ ì´ë¯¸ì§€ ì¶”ë¡ : {image_path}")
            prediction = inference_engine.predict_single(
                image_path=image_path,
                return_probabilities=True,
                top_k=1
            )
            
            if 'error' not in prediction:
                all_results.append({
                    'image_path': image_path,
                    'predicted_class': prediction['predicted_class'],
                    'confidence': round(prediction['confidence'], 3),  # ì†Œìˆ«ì  ì…‹ì§¸ìë¦¬
                    'true_class': 'N/A'  # ë‹¨ì¼ ì´ë¯¸ì§€ì˜ ê²½ìš° ì‹¤ì œ í´ë˜ìŠ¤ ì•Œ ìˆ˜ ì—†ìŒ
                })
            else:
                all_results.append({
                    'image_path': image_path,
                    'predicted_class': 'ERROR',
                    'confidence': 0.0,
                    'true_class': 'N/A'
                })
                
        elif csv_path:
            # CSV íŒŒì¼ì—ì„œ ë°°ì¹˜ ì˜ˆì¸¡
            logger.info(f"ë°°ì¹˜ ì¶”ë¡ : {csv_path}")
            df = pd.read_csv(csv_path)
            if 'image_path' not in df.columns:
                raise ValueError("CSV íŒŒì¼ì— 'image_path' ì»¬ëŸ¼ì´ í•„ìš”í•©ë‹ˆë‹¤")
            
            image_paths = df['image_path'].tolist()
            
            start_time = time.time()
            predictions = inference_engine.predict_batch(
                image_paths=image_paths,
                batch_size=batch_size,
                return_probabilities=True,
                top_k=1
            )
            end_time = time.time()
            
            total_time = end_time - start_time
            avg_time_per_image = total_time / len(image_paths) if len(image_paths) > 0 else 0
            logger.info(f"ë°°ì¹˜ ì¶”ë¡  ì‹œê°„: ì´ {total_time:.2f}ì´ˆ, ê°œë‹¹ í‰ê·  {avg_time_per_image:.3f}ì´ˆ")
            
            # true_class ì»¬ëŸ¼ì´ ìˆëŠ”ì§€ í™•ì¸
            has_true_class = 'image_type' in df.columns
            
            for i, pred in enumerate(predictions):
                true_class = df.iloc[i]['image_type'] if has_true_class and i < len(df) else 'N/A'
                
                if 'error' not in pred:
                    all_results.append({
                        'image_path': pred['image_path'],
                        'predicted_class': pred['predicted_class'],
                        'confidence': round(pred['confidence'], 3),  # ì†Œìˆ«ì  ì…‹ì§¸ìë¦¬
                        'true_class': true_class
                    })
                else:
                    all_results.append({
                        'image_path': pred['image_path'],
                        'predicted_class': 'ERROR',
                        'confidence': 0.0,
                        'true_class': true_class
                    })
                    
        else:
            # ì „ì²´ ë°ì´í„°ì…‹ ì¶”ë¡  (train/validation/test ëª¨ë‘)
            logger.info("ğŸ“Š ì „ì²´ ë°ì´í„°ì…‹ ì¶”ë¡  ì‹œì‘")
            
            data_dir = self.config.get('paths', {}).get('data_dir', 'data')
            splits = ['train', 'validation', 'test']
            
            for split_name in splits:
                split_file = os.path.join(data_dir, f'{split_name}_data.csv')
                
                if not os.path.exists(split_file):
                    logger.warning(f"{split_name} ë°ì´í„° íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {split_file}")
                    continue
                
                logger.info(f"ğŸ“Š {split_name.upper()} ë°ì´í„°ì…‹ ì¶”ë¡  ì¤‘...")
                
                try:
                    split_df = pd.read_csv(split_file)
                    image_paths = split_df['image_path'].tolist()
                    
                    start_time = time.time()
                    predictions = inference_engine.predict_batch(
                        image_paths=image_paths,
                        batch_size=batch_size,
                        return_probabilities=True,
                        top_k=1
                    )
                    end_time = time.time()
                    
                    total_time = end_time - start_time
                    avg_time_per_image = total_time / len(image_paths) if len(image_paths) > 0 else 0
                    logger.info(f"{split_name.upper()} ì¶”ë¡  ì‹œê°„: ì´ {total_time:.2f}ì´ˆ, ê°œë‹¹ í‰ê·  {avg_time_per_image:.3f}ì´ˆ")
                    
                    # ì •í™•ë„ ê³„ì‚°
                    if 'image_type' in split_df.columns:
                        correct = 0
                        total = 0
                        for i, pred in enumerate(predictions):
                            if 'error' not in pred and i < len(split_df):
                                actual = split_df.iloc[i]['image_type']
                                predicted = pred['predicted_class']
                                if actual == predicted:
                                    correct += 1
                                total += 1
                        
                        if total > 0:
                            accuracy = correct / total
                            logger.info(f"{split_name.upper()} ì •í™•ë„: {accuracy:.4f} ({correct}/{total})")
                    
                    # ê²°ê³¼ ì¶”ê°€
                    for i, pred in enumerate(predictions):
                        true_class = split_df.iloc[i]['image_type'] if i < len(split_df) else 'N/A'
                        
                        if 'error' not in pred:
                            all_results.append({
                                'image_path': pred['image_path'],
                                'predicted_class': pred['predicted_class'],
                                'confidence': round(pred['confidence'], 3),  # ì†Œìˆ«ì  ì…‹ì§¸ìë¦¬
                                'true_class': true_class
                            })
                        else:
                            all_results.append({
                                'image_path': pred['image_path'],
                                'predicted_class': 'ERROR',
                                'confidence': 0.0,
                                'true_class': true_class
                            })
                            
                except Exception as e:
                    logger.error(f"{split_name} ì¶”ë¡  ì‹¤íŒ¨: {e}")
        
        # ê²°ê³¼ë¥¼ DataFrameìœ¼ë¡œ ë³€í™˜
        result_df = pd.DataFrame(all_results)
        
        # ë©”ì¸ ê²°ê³¼ íŒŒì¼ ì €ì¥ (run í´ë” ì•ˆì—)
        if output_path:
            output_file = os.path.join(self.run_dir, os.path.basename(output_path))
        else:
            timestamp = self.start_time.strftime("%Y%m%d_%H%M%S")
            output_file = os.path.join(self.run_dir, f"inference_results_{timestamp}.csv")
        
        result_df.to_csv(output_file, index=False, encoding='utf-8')
        
        # í‹€ë¦° ê²°ê³¼ë§Œ ëª¨ì•„ì„œ wrong_*.csv íŒŒì¼ ìƒì„±
        self._create_wrong_result_csvs(result_df)
        
        logger.info("=" * 60)
        logger.info("âœ… ì¶”ë¡  ì™„ë£Œ")
        logger.info(f"ğŸ“ ê²°ê³¼ íŒŒì¼: {output_file}")
        logger.info(f"ğŸ“Š ì´ {len(all_results)}ê°œ ê²°ê³¼")
        logger.info("=" * 60)
        
        return output_file
    
    def _create_wrong_result_csvs(self, result_df: pd.DataFrame):
        """í‹€ë¦° ê²°ê³¼ë§Œ ëª¨ì•„ì„œ wrong_*.csv íŒŒì¼ë“¤ ìƒì„±"""
        
        # ì „ì²´ ê²°ê³¼ì—ì„œ í‹€ë¦° ê²ƒë§Œ ì¶”ì¶œ (ERRORì™€ N/AëŠ” ì œì™¸)
        wrong_results = result_df[
            (result_df['true_class'] != 'N/A') & 
            (result_df['predicted_class'] != 'ERROR') &
            (result_df['predicted_class'] != result_df['true_class'])
        ].copy()
        
        if len(wrong_results) == 0:
            logger.info("ğŸ‰ ëª¨ë“  ì˜ˆì¸¡ì´ ì •í™•í•©ë‹ˆë‹¤! wrong_*.csv íŒŒì¼ì´ ìƒì„±ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
            return
        
        # confidence í° ìˆœìœ¼ë¡œ ì •ë ¬
        wrong_results = wrong_results.sort_values('confidence', ascending=False)
        
        # ê° splitë³„ë¡œ ë¶„ë¦¬í•˜ì—¬ ì €ì¥
        splits = ['train', 'valid', 'test']
        
        for split in splits:
            # í•´ë‹¹ splitì˜ ì´ë¯¸ì§€ ê²½ë¡œë“¤ì„ í™•ì¸
            if split == 'valid':
                split_file = "data/validation_data.csv"
            else:
                split_file = f"data/{split}_data.csv"
            
            if os.path.exists(split_file):
                try:
                    split_df = pd.read_csv(split_file)
                    split_image_paths = set(split_df['image_path'].tolist())
                    
                    # í•´ë‹¹ splitì˜ í‹€ë¦° ê²°ê³¼ë§Œ í•„í„°ë§
                    split_wrong = wrong_results[wrong_results['image_path'].isin(split_image_paths)]
                    
                    if len(split_wrong) > 0:
                        wrong_file = os.path.join(self.run_dir, f"wrong_{split}.csv")
                        split_wrong.to_csv(wrong_file, index=False, encoding='utf-8')
                        logger.info(f"ğŸ“„ {split.upper()} í‹€ë¦° ê²°ê³¼: {wrong_file} ({len(split_wrong)}ê°œ)")
                    else:
                        logger.info(f"ğŸ‰ {split.upper()} ë°ì´í„°ì…‹: ëª¨ë“  ì˜ˆì¸¡ì´ ì •í™•í•©ë‹ˆë‹¤!")
                        
                except Exception as e:
                    logger.warning(f"âš ï¸ {split} wrong ê²°ê³¼ ìƒì„± ì‹¤íŒ¨: {e}")
            else:
                logger.warning(f"âš ï¸ {split} ë°ì´í„° íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {split_file}")
        
        logger.info(f"ğŸ“Š ì „ì²´ í‹€ë¦° ê²°ê³¼: {len(wrong_results)}ê°œ (confidence ë†’ì€ ìˆœ ì •ë ¬)")


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(description='ì´ë¯¸ì§€ íƒ€ì… ë¶„ë¥˜ í…ŒìŠ¤íŠ¸ - ë‹¨ìˆœ CSV ê²°ê³¼ ìƒì„±')
    parser.add_argument('--config', type=str, default='config.json',
                       help='ì„¤ì • íŒŒì¼ ê²½ë¡œ (ê¸°ë³¸ê°’: config.json)')
    parser.add_argument('--model-path', type=str, required=True,help='ì‚¬ìš©í•  ëª¨ë¸ íŒŒì¼ ê²½ë¡œ (í•„ìˆ˜)')
    parser.add_argument('--image-path', type=str,
                       help='ì¶”ë¡ í•  ì´ë¯¸ì§€ ê²½ë¡œ (ë‹¨ì¼ ì´ë¯¸ì§€ìš©)')
    parser.add_argument('--csv-path', type=str,
                       help='ë°°ì¹˜ ì¶”ë¡ í•  CSV íŒŒì¼ ê²½ë¡œ')
    parser.add_argument('--output-path', type=str,
                       help='ì¶”ë¡  ê²°ê³¼ ì €ì¥ ê²½ë¡œ (CSV íŒŒì¼)')
    
    args = parser.parse_args()
    
    try:
        # í…ŒìŠ¤íŠ¸ íŒŒì´í”„ë¼ì¸ ìƒì„±
        test_pipeline = ImageTypeClassificationTest(config_path=args.config)
        
        # ì¶”ë¡  ì‹¤í–‰
        output_file = test_pipeline.run_inference(
            image_path=args.image_path,
            csv_path=args.csv_path,
            output_path=args.output_path,
            model_path=args.model_path
        )
        
        print(f"\nğŸ” ì¶”ë¡  ì™„ë£Œ!")
        print(f"ğŸ“ ê²°ê³¼ íŒŒì¼: {output_file}")
            
    except Exception as e:
        logger.error(f"í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()
